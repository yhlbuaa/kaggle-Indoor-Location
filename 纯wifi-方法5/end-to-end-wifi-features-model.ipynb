{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":22559,"databundleVersionId":1923081,"sourceType":"competition"},{"sourceId":2239512,"sourceType":"datasetVersion","datasetId":1296260}],"dockerImageVersionId":30086,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is my attempt at putting together one end to end notebook for using models on wifi features. Thanks @deviananzelmo,  @higepon and @jiweiliu for sharing your notebooks on wifi features\n\n1. setting up a config class to tune parameters easily\n2. Deterministic seed function for torch users\n3. LR range finder function\n4. This includes reading data, creating Pytorch Datasets and Dataloaders\n5. Pytorch model to fit (in this case a simple MLP model)\n6. Choosing cv strategy (group kfold seems correct for the competition)\n7. train models according to building wifi features Data\n8. Generate OOF predictions from each fold's validation data\n9. Predicting for Test set \n10. plotting training results \n\nIf your're new to OOF concept, try reading [chris doette's wonderful post on hill climbing method](https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/175614)\n\n\nAs of now I haven't added any post processing, but will try to add it here if time permits","metadata":{}},{"cell_type":"markdown","source":"## Library imports","metadata":{}},{"cell_type":"code","source":"!pip install pickle5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:47.662109Z","iopub.execute_input":"2025-03-25T03:33:47.662513Z","iopub.status.idle":"2025-03-25T03:33:53.637861Z","shell.execute_reply.started":"2025-03-25T03:33:47.662479Z","shell.execute_reply":"2025-03-25T03:33:53.636573Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pickle5 in /opt/conda/lib/python3.7/site-packages (0.0.12)\n","output_type":"stream"}],"execution_count":132},{"cell_type":"code","source":"# basic imports\nimport os\nimport gc\nimport math\nimport glob\nimport random\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport pickle5 as pickle\nfrom tqdm.notebook import tqdm\n\n# DL library imports\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nfrom  torch.cuda.amp import autocast, GradScaler\n\n# metrics calculation\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GroupKFold\n\n# basic plotting library\nimport matplotlib.pyplot as plt\n\n# interactive plots\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import iplot\n\nimport warnings  \nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.640715Z","iopub.execute_input":"2025-03-25T03:33:53.641072Z","iopub.status.idle":"2025-03-25T03:33:53.648322Z","shell.execute_reply.started":"2025-03-25T03:33:53.641014Z","shell.execute_reply":"2025-03-25T03:33:53.647492Z"}},"outputs":[],"execution_count":133},{"cell_type":"markdown","source":"## Config parameters","metadata":{}},{"cell_type":"code","source":"class CFG:\n    # pipeline parameters\n    SEED        = 42\n    TRAIN       = True\n    LR_FIND     = False\n    TEST        = False\n    N_FOLDS     = 2 \n    N_EPOCHS    = 5\n    TEST_BATCH_SIZE  = 128\n    TRAIN_BATCH_SIZE = 64\n    NUM_WORKERS      = 4\n    DATA_FRAC        = 1.0\n    FOLD_TO_TRAIN    = [0, 1, 2, 3, 4] # \n\n    # model parameters\n    MODEL_ARCH  = 'MLP'\n    MODEL_NAME  = 'mlp_v1'\n    WGT_PATH    = ''\n    WGT_MODEL   = ''\n    PRINT_N_EPOCH = 2\n    \n    # scheduler variables\n    MAX_LR    = 1e-2\n    MIN_LR    = 1e-5\n    SCHEDULER = 'CosineAnnealingWarmRestarts'  # ['ReduceLROnPlateau', 'None', OneCycleLR','CosineAnnealingLR']\n    T_0       = 10     # CosineAnnealingWarmRestarts\n    T_MULT    = 2      # CosineAnnealingWarmRestarts\n    T_MAX     = 10      # CosineAnnealingLR\n\n    # optimizer variables\n    OPTIMIZER     = 'Adam'\n    WEIGHT_DECAY  = 1e-6\n    GRD_ACC_STEPS = 1\n    MAX_GRD_NORM  = 2\n\n    # features parameters\n    USE_FREQ_FEATS = False\n    USE_DT_FEATS   = False\n    \n    BUILDING_SITES_RANGE = [0,1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.649857Z","iopub.execute_input":"2025-03-25T03:33:53.650214Z","iopub.status.idle":"2025-03-25T03:33:53.668584Z","shell.execute_reply.started":"2025-03-25T03:33:53.650184Z","shell.execute_reply":"2025-03-25T03:33:53.667767Z"}},"outputs":[],"execution_count":134},{"cell_type":"code","source":"floor_map = {\"B2\": -2, \"B1\": -1, \"F1\": 0, \"F2\": 1, \"F3\": 2, \"F4\": 3, \"F5\": 4, \"F6\": 5, \"F7\": 6, \"F8\": 7, \"F9\": 8,\n             \"1F\": 0, \"2F\": 1, \"3F\": 2, \"4F\": 3, \"5F\": 4, \"6F\": 5, \"7F\": 6, \"8F\": 7, \"9F\": 8}\n\nminCount = 1\nfreqFillerValue = 0\nrssiFillerValue = -999.0\ndtFillerValue   = 1000.0\nmodelOutputDir = '.'\nwifiFeaturesDir_train = '../input/idln-mlp-wifi-features-dataset/wiFiFeatures/wiFiFeatures/train'\nwifiFeaturesDir_test  = '../input/idln-mlp-wifi-features-dataset/wiFiFeatures/wiFiFeatures/test'\nsampleCsvPath = '../input/indoor-location-navigation/sample_submission.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.669791Z","iopub.execute_input":"2025-03-25T03:33:53.670051Z","iopub.status.idle":"2025-03-25T03:33:53.682118Z","shell.execute_reply.started":"2025-03-25T03:33:53.670028Z","shell.execute_reply":"2025-03-25T03:33:53.681328Z"}},"outputs":[],"execution_count":135},{"cell_type":"markdown","source":"## Helper functions","metadata":{"papermill":{"duration":0.030885,"end_time":"2021-02-15T09:18:40.779692","exception":false,"start_time":"2021-02-15T09:18:40.748807","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def getBuildingName(buildingDataPath):\n    return buildingDataPath.split('/')[-1].split('_')[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.683461Z","iopub.execute_input":"2025-03-25T03:33:53.683831Z","iopub.status.idle":"2025-03-25T03:33:53.697991Z","shell.execute_reply.started":"2025-03-25T03:33:53.683793Z","shell.execute_reply":"2025-03-25T03:33:53.697023Z"}},"outputs":[],"execution_count":136},{"cell_type":"code","source":"def find_no_of_trainable_params(model):\n    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    return total_trainable_params","metadata":{"papermill":{"duration":0.040621,"end_time":"2021-02-15T09:18:40.851226","exception":false,"start_time":"2021-02-15T09:18:40.810605","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.701114Z","iopub.execute_input":"2025-03-25T03:33:53.701378Z","iopub.status.idle":"2025-03-25T03:33:53.712419Z","shell.execute_reply.started":"2025-03-25T03:33:53.701354Z","shell.execute_reply":"2025-03-25T03:33:53.711586Z"}},"outputs":[],"execution_count":137},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nset_seed(CFG.SEED)","metadata":{"papermill":{"duration":0.045466,"end_time":"2021-02-15T09:18:40.927741","exception":false,"start_time":"2021-02-15T09:18:40.882275","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.715733Z","iopub.execute_input":"2025-03-25T03:33:53.716153Z","iopub.status.idle":"2025-03-25T03:33:53.725693Z","shell.execute_reply.started":"2025-03-25T03:33:53.716109Z","shell.execute_reply":"2025-03-25T03:33:53.724849Z"}},"outputs":[],"execution_count":138},{"cell_type":"code","source":"\"\"\"\n#### rssi features is fixed, we can choose to use dt and freq features optionally\n# Incase freq signal is not needed, use rssi and dt features alone    \n# There are 5 columns for timestamp, (x,y), floor , pathNames values in csv, reamining are features\n# total features = 3 * [rssi, dt, freq]\n# hence unique wifi ids = totalFeatures / 3\n\"\"\"\ndef getBuildingFeatures(buildingData, dataType):\n    if dataType == 'train':\n        buildingData = buildingData.iloc[:,1:-4].values.astype(np.float16)\n    else:\n        buildingData = buildingData.iloc[:,1:-1].values.astype(np.float16)\n    \n    numBssids = int(buildingData.shape[1] / 3)\n    ## replace -999 with 99, 1000.0 with 50.0 and scale accordindly\n    buildingData[buildingData == -999.0] = -99.0\n    buildingData[buildingData == 1000.0] = 50.0\n    buildingData[:,0:numBssids]              = buildingData[:,0:numBssids] / 100.0\n    buildingData[:,numBssids: 2*numBssids]   = buildingData[:,numBssids: 2*numBssids] / 50.0\n    buildingData[:,2*numBssids: 3*numBssids] = buildingData[:,2*numBssids: 3*numBssids] / 1000.0\n\n    if CFG.USE_FREQ_FEATS == True:    \n        ## use all features\n        if CFG.USE_DT_FEATS == True:\n            X = buildingData\n        ## use rssi and freq features alone\n        else:\n            desiredFeatures = list(range(0, numBssids)) + list(range(2*numBssids, 3*numBssids))\n            X = buildingData[:, desiredFeatures]\n    else:\n        ## use only rssi features alone\n        if CFG.USE_DT_FEATS == True:\n            X = buildingData[:,0:2*numBssids]\n        ## use only rssi features alone\n        else:\n            X = buildingData[:,0:numBssids]\n    return X#默认只用rssi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.727030Z","iopub.execute_input":"2025-03-25T03:33:53.727420Z","iopub.status.idle":"2025-03-25T03:33:53.742079Z","shell.execute_reply.started":"2025-03-25T03:33:53.727383Z","shell.execute_reply":"2025-03-25T03:33:53.741236Z"}},"outputs":[],"execution_count":139},{"cell_type":"code","source":"def getBuildingData(buildingDataPath):\n    # read building data \n    #### data = pd.read_pickle(buildingDataPath)\n    with open(buildingDataPath, 'rb') as inputFile:\n        data = pickle.load(inputFile)    \n\n    \n    # use fraction if needed\n    if CFG.DATA_FRAC < 1:\n        data = data.sample(frac=CFG.DATA_FRAC).reset_index(drop=True)\n    print(\"数据：\",data.loc[0])\n    # first column is timestamp\n    timestamps = data.iloc[:,0].values   # np.expand_dims( , ,axis=1)\n    \n    # last column is pathFile name\n    groups = data.iloc[:,-1].values\n    \n    # target values are last but 3 columns\n    y = data.iloc[:,-4:-1].values\n    X = getBuildingFeatures(data,'train')\n    ## del data\n    ## gc.collect()\n    return timestamps,X,y,groups #timestamps为时间 X为特征 默认rssi 共（10175-5）/3个。， x为位置和floor, groups 为path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.743042Z","iopub.execute_input":"2025-03-25T03:33:53.743307Z","iopub.status.idle":"2025-03-25T03:33:53.759893Z","shell.execute_reply.started":"2025-03-25T03:33:53.743283Z","shell.execute_reply":"2025-03-25T03:33:53.759069Z"}},"outputs":[],"execution_count":140},{"cell_type":"code","source":"def getInputFeatureSize(featureFilesPath):\n    sampleData = np.load(f\"{npyWifiFeaturesDir}/{featureFilesPath[0]}\")\n    return len(sampleData)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.760926Z","iopub.execute_input":"2025-03-25T03:33:53.761185Z","iopub.status.idle":"2025-03-25T03:33:53.775279Z","shell.execute_reply.started":"2025-03-25T03:33:53.761161Z","shell.execute_reply":"2025-03-25T03:33:53.774131Z"}},"outputs":[],"execution_count":141},{"cell_type":"code","source":"def competitionMetric(preds, targets):\n    \"\"\" The metric used in this competition \"\"\"\n    # position error\n    meanPosPredictionError = torch.mean(torch.sqrt(\n                             torch.square(torch.subtract(preds[:,0], targets[:,0])) + \n                             torch.square(torch.subtract(preds[:,1], targets[:,1]))))\n    # error in floor prediction\n    meanFloorPredictionError = torch.mean(15 * torch.abs(preds[:,2] - targets[:,2]))\n    return meanPosPredictionError, meanFloorPredictionError","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.776444Z","iopub.execute_input":"2025-03-25T03:33:53.776758Z","iopub.status.idle":"2025-03-25T03:33:53.787611Z","shell.execute_reply.started":"2025-03-25T03:33:53.776725Z","shell.execute_reply":"2025-03-25T03:33:53.786768Z"}},"outputs":[],"execution_count":142},{"cell_type":"code","source":"def getOptimizer(model : nn.Module):    \n    if CFG.OPTIMIZER == 'Adam':\n        optimizer = optim.Adam(model.parameters(), weight_decay=CFG.WEIGHT_DECAY, lr=CFG.MAX_LR)\n    else:\n        optimizer = optim.SGD(model.parameters(), weight_decay=CFG.WEIGHT_DECAY, lr=CFG.MAX_LR, momentum=0.9)\n    return optimizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.788782Z","iopub.execute_input":"2025-03-25T03:33:53.789108Z","iopub.status.idle":"2025-03-25T03:33:53.799976Z","shell.execute_reply.started":"2025-03-25T03:33:53.789046Z","shell.execute_reply":"2025-03-25T03:33:53.799282Z"}},"outputs":[],"execution_count":143},{"cell_type":"code","source":"def getScheduler(optimizer, dataloader_train):\n    if CFG.SCHEDULER == 'OneCycleLR':\n        scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr= CFG.MAX_LR, epochs = CFG.N_EPOCHS, \n                          steps_per_epoch = len(dataloader_train), pct_start=0.25, div_factor=10, anneal_strategy='cos')\n    elif CFG.SCHEDULER == 'CosineAnnealingWarmRestarts':\n        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=CFG.T_MULT, eta_min=CFG.MIN_LR, last_epoch=-1)\n    elif CFG.SCHEDULER == 'CosineAnnealingLR':\n        scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_MAX * len(dataloader_train), eta_min=CFG.MIN_LR, last_epoch=-1)\n    else:\n        scheduler = None\n    return scheduler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.801400Z","iopub.execute_input":"2025-03-25T03:33:53.801681Z","iopub.status.idle":"2025-03-25T03:33:53.813609Z","shell.execute_reply.started":"2025-03-25T03:33:53.801655Z","shell.execute_reply":"2025-03-25T03:33:53.812779Z"}},"outputs":[],"execution_count":144},{"cell_type":"code","source":"def getDataLoader(dataset, datasetType : str):\n    if datasetType == 'train':\n        batchSize = CFG.TRAIN_BATCH_SIZE\n        shuffleDataset = True\n    else:\n        batchSize = CFG.TEST_BATCH_SIZE\n        shuffleDataset = False\n    \n    dataLoader = DataLoader(dataset, batch_size= batchSize, shuffle=shuffleDataset,\n                            num_workers=CFG.NUM_WORKERS, pin_memory=False, drop_last=False)\n    return dataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.815036Z","iopub.execute_input":"2025-03-25T03:33:53.815445Z","iopub.status.idle":"2025-03-25T03:33:53.831442Z","shell.execute_reply.started":"2025-03-25T03:33:53.815374Z","shell.execute_reply":"2025-03-25T03:33:53.830517Z"}},"outputs":[],"execution_count":145},{"cell_type":"code","source":"def plotTrainingResults(resultsDf, buildingName):\n    # subplot to plot\n    fig = make_subplots(rows=1, cols=1)\n    colors = [ ('#d32f2f', '#ef5350'), ('#303f9f', '#5c6bc0'), ('#00796b', '#26a69a'),\n                ('#fbc02d', '#ffeb3b'), ('#5d4037', '#8d6e63')]\n\n    # find number of folds input df\n    numberOfFolds = resultsDf['fold'].nunique()\n    \n    # iterate through folds and plot\n    for i in range(numberOfFolds):\n        data = resultsDf[resultsDf['fold'] == i]\n        fig.add_trace(go.Scatter(x=data['epoch'].values, y=data['trainPosLoss'].values,\n                                mode='lines', visible='legendonly' if i > 0 else True,\n                                line=dict(color=colors[i][0], width=2),\n                                name='{}-trainPossLoss-Fold{}'.format(buildingName, i)),row=1, col=1)\n\n        fig.add_trace(go.Scatter(x=data['epoch'], y=data['valPosLoss'].values,\n                                 mode='lines+markers', visible='legendonly' if i > 0 else True,\n                                 line=dict(color=colors[i][1], width=2),\n                                 name='{}-valPosLoss-Fold{}'.format(buildingName,i)),row=1, col=1)\n    fig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.832544Z","iopub.execute_input":"2025-03-25T03:33:53.832821Z","iopub.status.idle":"2025-03-25T03:33:53.843942Z","shell.execute_reply.started":"2025-03-25T03:33:53.832794Z","shell.execute_reply":"2025-03-25T03:33:53.843157Z"}},"outputs":[],"execution_count":146},{"cell_type":"markdown","source":"## Dataset class","metadata":{}},{"cell_type":"code","source":"class wiFiFeaturesDataset(Dataset):\n    def __init__(self, timeStamps, X_data, y_data, groups):\n        self.timeStamps = timeStamps \n        self.X_data = X_data\n        self.y_data = y_data\n        self.groups = groups\n        \n    def __getitem__(self, index):\n        x  = torch.from_numpy(self.X_data[index].astype(np.float32))\n        y  = torch.from_numpy(self.y_data[index].astype(np.float32))\n        ts = self.timeStamps[index].astype(np.int64)\n        group = self.groups[index]\n        return ts,x,y,group\n    \n    def __len__ (self):\n        return len(self.X_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.845277Z","iopub.execute_input":"2025-03-25T03:33:53.845568Z","iopub.status.idle":"2025-03-25T03:33:53.863503Z","shell.execute_reply.started":"2025-03-25T03:33:53.845523Z","shell.execute_reply":"2025-03-25T03:33:53.862577Z"}},"outputs":[],"execution_count":147},{"cell_type":"code","source":"class wiFiFeaturesDataset_test(Dataset):\n    def __init__(self, timeStamps, X_data, groups):\n        self.timeStamps = timeStamps \n        self.X_data = X_data\n        self.groups = groups\n        \n    def __getitem__(self, index):\n        x  = torch.from_numpy(self.X_data[index].astype(np.float32))\n        ts = self.timeStamps[index].astype(np.int64)\n        group = self.groups[index]\n        return ts,x,group\n    \n    def __len__ (self):\n        return len(self.X_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.865197Z","iopub.execute_input":"2025-03-25T03:33:53.865586Z","iopub.status.idle":"2025-03-25T03:33:53.878754Z","shell.execute_reply.started":"2025-03-25T03:33:53.865542Z","shell.execute_reply":"2025-03-25T03:33:53.877823Z"}},"outputs":[],"execution_count":148},{"cell_type":"markdown","source":"## MLP Model class","metadata":{}},{"cell_type":"code","source":"#MLP模型\nclass wiFiFeaturesMLPModel(nn.Module):\n    def __init__(self, n_input, n_output):\n        super().__init__()\n        self.lin1 = nn.Linear(in_features=n_input, out_features=512)\n        self.lin2 = nn.Linear(in_features=512,     out_features=32)\n        self.lin3 = nn.Linear(in_features=32,      out_features=n_output)\n        self.bn1 = nn.BatchNorm1d(512)\n        self.bn2 = nn.BatchNorm1d(32)\n        self.drops = nn.Dropout(0.3)        \n\n    def forward(self, x):\n        numBatches = x.shape[0]\n        \n        x = F.relu(self.lin1(x))\n        x = self.drops(x)\n        \n        ## batchnorm doesnt work for batchsize of 1\n        if numBatches > 1:\n            x = self.bn1(x)\n            x = F.relu(self.lin2(x))\n            x = self.drops(x)\n            x = self.bn2(x)\n            x = self.lin3(x)\n        else:\n            x = F.relu(self.lin2(x))\n            x = self.drops(x)\n            x = self.lin3(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.879973Z","iopub.execute_input":"2025-03-25T03:33:53.880340Z","iopub.status.idle":"2025-03-25T03:33:53.896161Z","shell.execute_reply.started":"2025-03-25T03:33:53.880302Z","shell.execute_reply":"2025-03-25T03:33:53.895350Z"}},"outputs":[],"execution_count":149},{"cell_type":"markdown","source":"## Lr range finder","metadata":{}},{"cell_type":"code","source":"def plot_lr_finder_results(lr_finder): \n    # Create subplot grid\n    fig = make_subplots(rows=1, cols=2)\n    # layout ={'title': 'Lr_finder_result'}\n    \n    # Create a line (trace) for the lr vs loss, gradient of loss\n    trace0 = go.Scatter(x=lr_finder['log_lr'], y=lr_finder['smooth_loss'],name='log_lr vs smooth_loss')\n    trace1 = go.Scatter(x=lr_finder['log_lr'], y=lr_finder['grad_loss'],name='log_lr vs loss gradient')\n\n    # Add subplot trace & assign to each grid\n    fig.add_trace(trace0, row=1, col=1);\n    fig.add_trace(trace1, row=1, col=2);\n    iplot(fig, show_link=False)\n    #fig.write_html(CFG.MODEL_NAME + '_lr_find.html');","metadata":{"papermill":{"duration":0.044791,"end_time":"2021-02-15T09:18:43.045246","exception":false,"start_time":"2021-02-15T09:18:43.000455","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.897483Z","iopub.execute_input":"2025-03-25T03:33:53.897759Z","iopub.status.idle":"2025-03-25T03:33:53.910251Z","shell.execute_reply.started":"2025-03-25T03:33:53.897721Z","shell.execute_reply":"2025-03-25T03:33:53.909415Z"}},"outputs":[],"execution_count":150},{"cell_type":"code","source":"def find_lr(model, optimizer, data_loader, init_value = 1e-8, final_value=100.0, beta = 0.98, num_batches = 200):\n    assert(num_batches > 0)\n    mult = (final_value / init_value) ** (1/num_batches)\n    lr = init_value\n    optimizer.param_groups[0]['lr'] = lr\n    batch_num = 0\n    avg_loss = 0.0\n    best_loss = 0.0\n    smooth_losses = []\n    raw_losses = []\n    log_lrs = []\n    dataloader_it = iter(data_loader)\n    progress_bar = tqdm(range(num_batches))                \n        \n    for idx in progress_bar:\n        batch_num += 1\n        try:\n            _, inputs, targets = next(dataloader_it)\n            #print(images.shape)\n        except:\n            dataloader_it = iter(data_loader)\n            _, inputs, targets = next(dataloader_it)\n\n        # Move input and label tensors to the default device\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n\n        # handle exception in criterion\n        try:\n            # Forward pass\n            y_preds = model(inputs)\n            posLoss, floorLoss = criterion(y_preds, targets)\n            loss = posLoss + floorLoss\n        except:\n            if len(smooth_losses) > 1:\n                grad_loss = np.gradient(smooth_losses)\n            else:\n                grad_loss = 0.0\n            lr_finder_results = {'log_lr':log_lrs, 'raw_loss':raw_losses, \n                                 'smooth_loss':smooth_losses, 'grad_loss': grad_loss}\n            return lr_finder_results \n                    \n        #Compute the smoothed loss\n        avg_loss = beta * avg_loss + (1-beta) *loss.item()\n        smoothed_loss = avg_loss / (1 - beta**batch_num)\n        \n        #Stop if the loss is exploding\n        if batch_num > 1 and smoothed_loss > 50 * best_loss:\n            if len(smooth_losses) > 1:\n                grad_loss = np.gradient(smooth_losses)\n            else:\n                grad_loss = 0.0\n            lr_finder_results = {'log_lr':log_lrs, 'raw_loss':raw_losses, \n                                 'smooth_loss':smooth_losses, 'grad_loss': grad_loss}\n            return lr_finder_results\n        \n        #Record the best loss\n        if smoothed_loss < best_loss or batch_num==1:\n            best_loss = smoothed_loss\n        \n        #Store the values\n        raw_losses.append(loss.item())\n        smooth_losses.append(smoothed_loss)\n        log_lrs.append(math.log10(lr))\n        \n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # print info\n        progress_bar.set_description(f\"loss:{loss.item()},smoothLoss: {smoothed_loss},lr:{lr}\")\n\n        #Update the lr for the next step\n        lr *= mult\n        optimizer.param_groups[0]['lr'] = lr\n    \n    grad_loss = np.gradient(smooth_losses)\n    lr_finder_results = {'log_lr':log_lrs, 'raw_loss':raw_losses, \n                         'smooth_loss':smooth_losses, 'grad_loss': grad_loss}\n    return lr_finder_results","metadata":{"papermill":{"duration":0.059229,"end_time":"2021-02-15T09:18:43.136586","exception":false,"start_time":"2021-02-15T09:18:43.077357","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.911674Z","iopub.execute_input":"2025-03-25T03:33:53.911937Z","iopub.status.idle":"2025-03-25T03:33:53.930425Z","shell.execute_reply.started":"2025-03-25T03:33:53.911911Z","shell.execute_reply":"2025-03-25T03:33:53.929641Z"}},"outputs":[],"execution_count":151},{"cell_type":"code","source":"if CFG.LR_FIND == True:\n    # create dataset instance\n    tempTs, tempX, tempY,_ = getBuildingData(buildingCsvPath=buildingsList[0])\n    tempX = stdScaler.fit_transform(tempX)\n    tempTrainDataset = wiFiFeaturesDataset(tempTs, tempX, tempY)\n    tempTrainDataloader = DataLoader(tempTrainDataset, batch_size= CFG.TRAIN_BATCH_SIZE, shuffle=True,\n                          num_workers=CFG.NUM_WORKERS, pin_memory=False, drop_last=False)\n    \n    # create model instance   \n    model = wiFiFeaturesMLPModel(n_input=tempX.shape[1], n_output=3)\n    model.to(device);\n    \n    # optimizer function, lr schedulers and loss function\n    optimizer = getOptimizer(model)\n    lrFinderResults = find_lr(model, optimizer, tempTrainDataloader)\n    plot_lr_finder_results(lrFinderResults)\n    del tempX, tempY, tempTrainDataset, tempTrainDataloader, model, optimizer","metadata":{"papermill":{"duration":0.048229,"end_time":"2021-02-15T09:18:43.217286","exception":false,"start_time":"2021-02-15T09:18:43.169057","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.931611Z","iopub.execute_input":"2025-03-25T03:33:53.931875Z","iopub.status.idle":"2025-03-25T03:33:53.947429Z","shell.execute_reply.started":"2025-03-25T03:33:53.931848Z","shell.execute_reply":"2025-03-25T03:33:53.946622Z"}},"outputs":[],"execution_count":152},{"cell_type":"markdown","source":"## Train & Validate helper functions","metadata":{}},{"cell_type":"code","source":"def validateModel(model, validationDataloader):\n    # placeholders to store output\n    val_ts = []\n    val_preds = []\n    val_targets = []\n    val_groups = []\n\n    # set model to Validate mode\n    model.eval()\n    dataLoaderIterator = iter(validationDataloader)\n\n    for idx in range(len(validationDataloader)):\n        try:\n            ts, inputs, targets, valGroups = next(dataLoaderIterator)\n        except StopIteration:\n            dataLoaderIterator = iter(validationDataloader)\n            ts, inputs, targets, valGroups = next(dataLoaderIterator)\n\n        inputs = inputs.to(device)\n        targets = targets.to(device) \n\n        # forward prediction\n        with torch.no_grad():    \n            y_preds = model(inputs)\n\n        # store predictions and targets to compute metrics later\n        val_ts.append(ts)\n        val_preds.append(y_preds)\n        val_targets.append(targets)\n        val_groups.append(valGroups)\n\n    # concatenate to get as 1 2d array and find total loss  \n    val_preds = torch.cat(val_preds, 0)\n    val_targets = torch.cat(val_targets, 0)\n    valPosLoss, valFloorLoss = criterion(val_preds, val_targets)\n    valScore = valPosLoss + valFloorLoss\n\n    # np array concatenation\n    val_ts = np.concatenate(val_ts, axis=0)\n    val_groups = np.concatenate(val_groups, axis=0)\n    \n    # store results\n    validationResults = {'valPosLoss': valPosLoss.item() , 'valFloorLoss': valFloorLoss.item(),\\\n                         'val_ts': val_ts, 'val_groups': val_groups,\n                         'val_preds'  :val_preds.cpu().data.numpy(), \n                         'val_targets':val_targets.cpu().data.numpy(),\n                         }\n    return validationResults","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.948613Z","iopub.execute_input":"2025-03-25T03:33:53.948882Z","iopub.status.idle":"2025-03-25T03:33:53.966436Z","shell.execute_reply.started":"2025-03-25T03:33:53.948856Z","shell.execute_reply":"2025-03-25T03:33:53.965668Z"}},"outputs":[],"execution_count":153},{"cell_type":"code","source":"def trainValidateOneFold(buildingName, i_fold, model, optimizer, scheduler, dataloader_train, dataloader_valid):\n    trainFoldResults = []\n    bestValScore = np.inf\n    bestEpoch = 0\n\n    for epoch in range(CFG.N_EPOCHS):\n        #print('Epoch {}/{}'.format(epoch + 1, CFG.N_EPOCHS))\n        model.train()\n        trainPosLoss = 0.0\n        trainFloorLoss = 0.0\n\n        # training iterator\n        tr_iterator = iter(dataloader_train)\n\n        for idx in range(len(dataloader_train)):\n            try:\n                _, inputs, targets, _ = next(tr_iterator)\n            except StopIteration:\n                tr_iterator = iter(dataloader_train)\n                _, inputs, targets, _ = next(tr_iterator)\n\n            inputs = inputs.to(device)\n            targets = targets.to(device)  \n\n            # builtin package to handle automatic mixed precision\n            with autocast():\n                # Forward pass\n                y_preds = model(inputs)   \n                posLoss, floorLoss = criterion(y_preds, targets)\n                loss = posLoss + floorLoss\n\n                # Backward pass\n                scaler.scale(loss).backward()        \n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad() \n\n                # log the necessary losses\n                trainPosLoss   += posLoss.item()\n                trainFloorLoss += floorLoss.item()\n\n                if scheduler is not None: \n                    if CFG.SCHEDULER == 'CosineAnnealingWarmRestarts':\n                        scheduler.step(epoch + idx / len(dataloader_train)) \n                    # onecyle lr scheduler / CosineAnnealingLR scheduler\n                    else:\n                        scheduler.step()\n                    \n        # Validate\n        foldValidationResults = validateModel(model, dataloader_valid)\n         \n        # store results\n        trainFoldResults.append({ 'fold': i_fold, 'epoch': epoch, \n                                  'trainPosLoss': trainPosLoss / len(dataloader_train), \n                                  'trainFloorLoss': trainFloorLoss / len(dataloader_train), \n                                  'valPosLoss'  : foldValidationResults['valPosLoss'] , \n                                  'valFloorLoss': foldValidationResults['valFloorLoss']})\n        \n        valScore = foldValidationResults['valPosLoss'] # + foldVal['valFloorLoss']\n        # save best models        \n        if(valScore < bestValScore):\n            # reset variables\n            bestValScore = valScore\n            bestEpoch = epoch\n\n            # save model weights\n            torch.save({'model': model.state_dict(), 'val_ts' : foldValidationResults['val_ts'], \n                        'val_preds':foldValidationResults['val_preds'], \n                        'val_targets':foldValidationResults['val_targets'],\n                        'val_groups' : foldValidationResults['val_groups']}, \n                        f\"{modelOutputDir}/{buildingName}_{CFG.MODEL_NAME}_fold{i_fold}_best.pth\")\n\n    print(f\"For Fold {i_fold}, Best validation score of {bestValScore} was got at epoch {bestEpoch}\") \n    return trainFoldResults","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.967564Z","iopub.execute_input":"2025-03-25T03:33:53.967849Z","iopub.status.idle":"2025-03-25T03:33:53.988833Z","shell.execute_reply.started":"2025-03-25T03:33:53.967820Z","shell.execute_reply":"2025-03-25T03:33:53.987879Z"}},"outputs":[],"execution_count":154},{"cell_type":"code","source":"def trainValidateOneBuilding(buildingDataPath, modelToFit):\n    # placeholder to store results\n    buildingTrainResults = []\n    \n    buildingName = getBuildingName(buildingDataPath)\n    print(f\"Processing data for building - {buildingName}\")\n    timestamps, X, y, groups = getBuildingData(buildingDataPath)#timestamps为时间, X为特征 默认rssi 共（10175-5）/3个,  y为位置和floor, groups 为path\n    print(f\"Building Data shapes : {timestamps.shape, X.shape, y.shape, groups.shape}\")#维度((9296,), (9296, 3390), (9296, 3), (9296,))\n\n    for i_fold, (trainIndex, validIndex) in enumerate(folds.split(X=X, y=y[:,0],groups=groups)):#交叉验证 ，同一个path 不同时在train 和valid中\n        if i_fold in CFG.FOLD_TO_TRAIN:\n            ## print(\"Fold {}/{}\".format(i_fold + 1, CFG.N_FOLDS))\n            \n            # splitting into train and validataion sets\n            trainTimeStamps, X_train, y_train, trainGroups = timestamps[trainIndex], X[trainIndex], y[trainIndex], groups[trainIndex]\n            validTimeStamps, X_valid, y_valid, validGroups = timestamps[validIndex], X[validIndex], y[validIndex], groups[validIndex] \n                        \n            # create torch Datasets and Dataloader for each fold's train and validation data\n            dataset_train = wiFiFeaturesDataset(trainTimeStamps, X_train, y_train, trainGroups)\n            dataset_valid = wiFiFeaturesDataset(validTimeStamps, X_valid, y_valid, validGroups)            \n            dataloader_train = getDataLoader(dataset_train, datasetType= 'train')\n            dataloader_valid = getDataLoader(dataset_valid, datasetType= 'valid')\n            \n            # supervised model instance and move to compute device\n            model = modelToFit(n_input=X.shape[1], n_output=3)\n            model.to(device);\n            ### print(f\"there are {find_no_of_trainable_params(model)} params in model\")\n\n            # optimizer function, lr schedulers and loss function\n            optimizer = getOptimizer(model)\n            scheduler = getScheduler(optimizer, dataloader_train)\n            # print(f\"optimizer={optimizer}, scheduler={scheduler}, loss_fn={criterion}\")\n\n            # train and validate single fold\n            foldResults = trainValidateOneFold(buildingName, i_fold, model, optimizer, scheduler,dataloader_train, dataloader_valid)\n            buildingTrainResults = buildingTrainResults + foldResults\n            \n            ## del trainTimeStamps, X_train, y_train, trainGroups\n            ## del validTimeStamps, X_valid, y_valid, validGroups\n            ## del dataloader_train, dataloader_valid, model, optimizer, scheduler\n            ## gc.collect()\n    \n    ## del timestamps, X, y, groups\n    ## gc.collect()\n    \n    buildingTrainResults = pd.DataFrame(buildingTrainResults)\n    buildingTrainResults['valTotalLoss'] = buildingTrainResults['valPosLoss'] + buildingTrainResults['valFloorLoss']\n    buildingTrainResults['trainTotalLoss'] = buildingTrainResults['trainPosLoss'] + buildingTrainResults['trainFloorLoss']\n    return buildingTrainResults","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:53.990305Z","iopub.execute_input":"2025-03-25T03:33:53.990584Z","iopub.status.idle":"2025-03-25T03:33:54.009638Z","shell.execute_reply.started":"2025-03-25T03:33:53.990557Z","shell.execute_reply":"2025-03-25T03:33:54.008802Z"}},"outputs":[],"execution_count":155},{"cell_type":"code","source":"def getFoldBestResultsDf(trainResults):\n    bestResults = []\n    numFolds = trainResults['fold'].nunique()\n    \n    for fold in range(numFolds):\n        foldDf = trainResults[trainResults['fold']== fold]\n        bestResults.append(foldDf.iloc[np.argmin(foldDf['valTotalLoss'].values),:])\n    \n    bestResults =pd.DataFrame(bestResults)\n    valPosLossBest = bestResults['valPosLoss'].values\n    print(f\"Best valPosLoss for all folds = {valPosLossBest}\")\n    print(f\"Mean, std ={valPosLossBest.mean()}, {valPosLossBest.std()}\")\n    return bestResults","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:54.010637Z","iopub.execute_input":"2025-03-25T03:33:54.010890Z","iopub.status.idle":"2025-03-25T03:33:54.031082Z","shell.execute_reply.started":"2025-03-25T03:33:54.010866Z","shell.execute_reply":"2025-03-25T03:33:54.030179Z"}},"outputs":[],"execution_count":156},{"cell_type":"markdown","source":"## Generate OOF function","metadata":{}},{"cell_type":"code","source":"def generateOOF(modelSaveDir:str, buildingName:str, modelName:str):\n    oof_ts = []\n    oof_preds = []\n    oof_targets = []\n    oof_groups = []\n    oof_folds = []\n\n    modelPaths = sorted(glob.glob(f\"{modelSaveDir}/{buildingName}_{modelName}_fold*.pth\"))\n\n    for fold in range(len(modelPaths)):\n        # load building-model-fold checkpoint\n        checkPoint = torch.load(modelPaths[fold], map_location=torch.device(device))\n        numRows = len(checkPoint['val_ts'])\n\n        oof_ts.append(checkPoint['val_ts'])\n        oof_preds.append(checkPoint['val_preds'])\n        oof_targets.append(checkPoint['val_targets'])\n        oof_groups.append(checkPoint['val_groups'])\n        oof_folds.append([fold] * numRows)\n    \n    oof_ts = np.concatenate(oof_ts,axis=0)\n    oof_preds = np.concatenate(oof_preds,axis=0)\n    oof_targets = np.concatenate(oof_targets,axis=0)\n    oof_groups = np.concatenate(oof_groups,axis=0)\n    oof_folds = np.concatenate(oof_folds,axis=0)\n    \n    #print(oof_ts.shape, oof_preds.shape, oof_targets.shape, oof_groups.shape, oof_folds.shape)\n    oof_df = pd.DataFrame({'timestamp' : oof_ts, 'x_preds': oof_preds[:,0], 'y_preds': oof_preds[:,1],\n                       'floor_preds': oof_preds[:,2], 'x_tgt': oof_targets[:,0], 'y_tgt': oof_targets[:,1],\n                       'floor_tgt': oof_targets[:,2], 'path' : oof_groups, 'fold' : oof_folds\n                      })\n    print(f\"OOF prediction for {buildingName} site generated\")\n    return oof_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:54.032252Z","iopub.execute_input":"2025-03-25T03:33:54.032519Z","iopub.status.idle":"2025-03-25T03:33:54.050873Z","shell.execute_reply.started":"2025-03-25T03:33:54.032496Z","shell.execute_reply":"2025-03-25T03:33:54.049848Z"}},"outputs":[],"execution_count":157},{"cell_type":"markdown","source":"## Test set prediction function","metadata":{}},{"cell_type":"code","source":"def generateWiFiSubmission(modelToFit, modelSaveDir:str, buildingName:str, modelName:str):\n    modelPaths = sorted(glob.glob(f\"{modelSaveDir}/{buildingName}_{modelName}_fold*.pth\"))\n    buildingTestData = f\"{wifiFeaturesDir_test}/{buildingName}_test.pickle\"\n    with open(buildingTestData, 'rb') as inputFile:\n        testData = pickle.load(inputFile)    \n    \n    test_ts = []\n    test_fold = []\n    test_preds = []\n    test_groups = []\n\n    for fold in range(CFG.N_FOLDS):\n        ## print(f\"Fold {fold} processing\")\n        #print(f\"Before stdscaler : testX mean = {testX.mean()}, testData std = {testX.std()}\")\n        testGroups = testData.iloc[:,-1].values    \n        testTimestamps = testData.iloc[:,0].values        \n        testX = getBuildingFeatures(testData, 'test')  \n        \n        checkPoint = torch.load(modelPaths[fold], map_location=torch.device(device))\n        model = modelToFit(n_input=testX.shape[1], n_output=3)\n        model.to(device);\n        model.load_state_dict(checkPoint['model'])\n\n        # set model to Validate mode\n        model.eval()\n        ## test Dataset and data loaders\n        testDataset = wiFiFeaturesDataset_test(testTimestamps, testX, testGroups)\n        testDataloader = getDataLoader(testDataset, datasetType= 'test')\n\n        dataLoaderIterator = iter(testDataloader)\n        for idx in range(len(testDataloader)):\n            try:\n                ts, inputs, testGroups = next(dataLoaderIterator)\n            except StopIteration:\n                dataLoaderIterator = iter(testDataloader)\n                ts, inputs, testGroups = next(dataLoaderIterator)\n\n            inputs = inputs.to(device)\n            # forward prediction\n            with torch.no_grad():    \n                y_preds = model(inputs)\n\n            # store predictions and targets to compute metrics later\n            test_ts.append(ts)\n            test_preds.append(y_preds)\n            test_groups.append(testGroups)\n        \n        test_fold.append([fold] * len(testX))\n        ## del testDataloader\n        ## torch.cuda.empty_cache()\n        ## gc.collect()\n        \n    # concatenate to get as 1 2d array \n    test_preds = torch.cat(test_preds, 0).cpu().data.numpy() \n    test_ts = np.concatenate(test_ts, axis=0)\n    test_fold = np.concatenate(test_fold, axis=0)\n    test_groups = np.concatenate(test_groups, axis=0)\n    subm_wifi_df = pd.DataFrame({'timestamp' : test_ts, 'x_preds': test_preds[:,0], 'y_preds': test_preds[:,1],\n                                 'floor_preds': test_preds[:,2], 'path' : test_groups, 'fold' : test_fold})\n    subm_wifi_df.to_pickle(f\"{buildingName}_wifi_subm.pickle\")  \n    print(f\"Test data prediction for {buildingName} site generated\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:54.052109Z","iopub.execute_input":"2025-03-25T03:33:54.052395Z","iopub.status.idle":"2025-03-25T03:33:54.065567Z","shell.execute_reply.started":"2025-03-25T03:33:54.052367Z","shell.execute_reply":"2025-03-25T03:33:54.064519Z"}},"outputs":[],"execution_count":158},{"cell_type":"markdown","source":"## Compute Device as CPU or GPU","metadata":{}},{"cell_type":"code","source":"## Device as cpu or tpu\ndevice = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device('cpu')\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:54.066844Z","iopub.execute_input":"2025-03-25T03:33:54.067144Z","iopub.status.idle":"2025-03-25T03:33:54.084554Z","shell.execute_reply.started":"2025-03-25T03:33:54.067115Z","shell.execute_reply":"2025-03-25T03:33:54.083743Z"}},"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}],"execution_count":159},{"cell_type":"markdown","source":"## Preprocessing classes","metadata":{}},{"cell_type":"code","source":"# for cv\n#交叉验证分组\nfolds = GroupKFold(n_splits=CFG.N_FOLDS)\n\n# scaler to handle AMP\nscaler = GradScaler()   \n\ncriterion = competitionMetric\nmodelToFit = wiFiFeaturesMLPModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:54.085923Z","iopub.execute_input":"2025-03-25T03:33:54.086209Z","iopub.status.idle":"2025-03-25T03:33:54.096772Z","shell.execute_reply.started":"2025-03-25T03:33:54.086182Z","shell.execute_reply":"2025-03-25T03:33:54.096044Z"}},"outputs":[],"execution_count":160},{"cell_type":"markdown","source":"## Training & Validation main function","metadata":{}},{"cell_type":"code","source":"%%time\nif CFG.TRAIN == True:\n    \n    buildingPathList_train = sorted(glob.glob(f\"{wifiFeaturesDir_train}/*.pickle\"))\n    buildingPathList_train = buildingPathList_train[CFG.BUILDING_SITES_RANGE[0]: CFG.BUILDING_SITES_RANGE[1]]\n    print(f\"{len(buildingPathList_train)} sites are to be trained\")\n    print(buildingPathList_train)\n\n    for number,buildingPath_train in enumerate(buildingPathList_train):\n        \n        print(f'{number}----------------------------------')\n        ## get building name\n        buildingName = getBuildingName(buildingPath_train)\n        \n        ## train and validate for building data\n        buildingTrainResults = trainValidateOneBuilding(buildingPath_train, modelToFit)\n        bestResults = getFoldBestResultsDf(buildingTrainResults)\n        \n        ## generate OOF prediction for building-model combination\n        buildingOOF = generateOOF(modelOutputDir, buildingName, CFG.MODEL_NAME)\n        \n        ## prediction for test data too\n        generateWiFiSubmission(modelToFit, modelOutputDir, buildingName, CFG.MODEL_NAME)\n\n        ## save results to file\n        buildingOOF.to_pickle(f\"{modelOutputDir}/{buildingName}_{CFG.MODEL_NAME}_OOF.pickle\")\n        bestResults.to_pickle(f\"{modelOutputDir}/{buildingName}_{CFG.MODEL_NAME}_bestResults.pickle\")\n        buildingTrainResults.to_pickle(f\"{modelOutputDir}/{buildingName}_{CFG.MODEL_NAME}_trainResults.pickle\")\n        \n        ## plot building results\n        plotTrainingResults(buildingTrainResults, buildingName)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:33:54.098315Z","iopub.execute_input":"2025-03-25T03:33:54.098673Z","iopub.status.idle":"2025-03-25T03:34:17.197404Z","shell.execute_reply.started":"2025-03-25T03:33:54.098634Z","shell.execute_reply":"2025-03-25T03:34:17.196450Z"}},"outputs":[{"name":"stdout","text":"1 sites are to be trained\n['../input/idln-mlp-wifi-features-dataset/wiFiFeatures/wiFiFeatures/train/5a0546857ecc773753327266_train.pickle']\n0----------------------------------\nProcessing data for building - 5a0546857ecc773753327266\n数据： 0                   1578467411228\n1                            -999\n2                            -999\n3                            -999\n4                            -999\n                   ...           \n10170                           0\n10171                     106.034\n10172                     162.169\n10173                          -1\n10174    5e1580adf4c3420006d520d4\nName: 0, Length: 10175, dtype: object\nBuilding Data shapes : ((9296,), (9296, 3390), (9296, 3), (9296,))\nFor Fold 0, Best validation score of 57.42298889160156 was got at epoch 3\nFor Fold 1, Best validation score of 60.09745407104492 was got at epoch 4\nBest valPosLoss for all folds = [57.42298889 60.09745407]\nMean, std =58.76022148132324, 1.3372325897216797\nOOF prediction for 5a0546857ecc773753327266 site generated\nTest data prediction for 5a0546857ecc773753327266 site generated\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"0f0dfe4a-b121-49e3-9a98-9db42efcbd7c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0f0dfe4a-b121-49e3-9a98-9db42efcbd7c\")) {                    Plotly.newPlot(                        \"0f0dfe4a-b121-49e3-9a98-9db42efcbd7c\",                        [{\"line\": {\"color\": \"#d32f2f\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"5a0546857ecc773753327266-trainPossLoss-Fold0\", \"type\": \"scatter\", \"visible\": true, \"x\": [0, 1, 2, 3, 4], \"xaxis\": \"x\", \"y\": [130.91691944697132, 80.18865867510233, 61.39308579327309, 58.77618794898464, 56.585340212469234], \"yaxis\": \"y\"}, {\"line\": {\"color\": \"#ef5350\", \"width\": 2}, \"mode\": \"lines+markers\", \"name\": \"5a0546857ecc773753327266-valPosLoss-Fold0\", \"type\": \"scatter\", \"visible\": true, \"x\": [0, 1, 2, 3, 4], \"xaxis\": \"x\", \"y\": [128.772705078125, 65.16868591308594, 62.49456787109375, 57.42298889160156, 59.32963562011719], \"yaxis\": \"y\"}, {\"line\": {\"color\": \"#303f9f\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"5a0546857ecc773753327266-trainPossLoss-Fold1\", \"type\": \"scatter\", \"visible\": \"legendonly\", \"x\": [0, 1, 2, 3, 4], \"xaxis\": \"x\", \"y\": [143.5466392203553, 85.87981012422745, 62.333226765671824, 61.4965358368338, 61.084587724241494], \"yaxis\": \"y\"}, {\"line\": {\"color\": \"#5c6bc0\", \"width\": 2}, \"mode\": \"lines+markers\", \"name\": \"5a0546857ecc773753327266-valPosLoss-Fold1\", \"type\": \"scatter\", \"visible\": \"legendonly\", \"x\": [0, 1, 2, 3, 4], \"xaxis\": \"x\", \"y\": [110.98255157470703, 61.25057601928711, 61.54684829711914, 65.61365509033203, 60.09745407104492], \"yaxis\": \"y\"}],                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('0f0dfe4a-b121-49e3-9a98-9db42efcbd7c');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}},{"name":"stdout","text":"CPU times: user 15.3 s, sys: 5.11 s, total: 20.4 s\nWall time: 23.1 s\n","output_type":"stream"}],"execution_count":161},{"cell_type":"markdown","source":"```python\nbuildingPathList_train = sorted(glob.glob(f\"{wifiFeaturesDir_train}/*.pickle\"))\nbuildingPathList_test = sorted(glob.glob(f\"{wifiFeaturesDir_test}/*.pickle\"))\n\nfor idx in range(len(buildingPathList_train)):\n    print('-----------------------------')\n    trainFilePath = buildingPathList_train[idx]\n    testFilePath  = buildingPathList_test[idx]\n    print(f\"{idx}. {getBuildingName(trainFilePath)}\")\n    with open(trainFilePath, 'rb') as inputTrainFile:\n        trainData = pickle.load(inputTrainFile)\n    with open(testFilePath, 'rb') as inputTestFile:\n        testData = pickle.load(inputTestFile)\n    \n    with pd.option_context('display.max_rows', 1, 'display.max_columns', 12,\n                           'display.width', 500, 'display.precision', 3,\n                           'display.colheader_justify', 'left'):\n        display(trainData)\n        display(testData)\n```        ","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}