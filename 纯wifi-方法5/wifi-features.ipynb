{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":22559,"databundleVersionId":1923081,"sourceType":"competition"}],"dockerImageVersionId":30055,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Wifi features\n\nThis this is the code to generate the wifi features available in [this dataset](https://www.kaggle.com/devinanzelmo/indoor-navigation-and-location-wifi-features). Using these features can get a score below 14. For an example notebook using them see [this notebook](https://www.kaggle.com/devinanzelmo/wifi-features-lightgbm-starter). They only uses waypoints, wifi and timestamp data to generate solution. See this [forum post](https://www.kaggle.com/c/indoor-location-navigation/discussion/215445) for an outline of this solution method, and methods of improvement.\n\nThere are `break`'s inserted into loops which need to be removed to get this to run. Right now data is written to current working directory. This takes 2-4 hours to run depending on hard drive etc. There is a lot of room for improvement speeding up feature generation. \n\n**Update:** I added one line that creates a column for the path filename, this allows for a groupkfold crossvalidation. \n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport glob\nimport os\nimport gc\nimport json ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-25T02:29:56.963219Z","iopub.execute_input":"2025-03-25T02:29:56.963684Z","iopub.status.idle":"2025-03-25T02:29:56.968999Z","shell.execute_reply.started":"2025-03-25T02:29:56.963577Z","shell.execute_reply":"2025-03-25T02:29:56.968030Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"base_path = '../input/indoor-location-navigation/'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T02:29:59.669468Z","iopub.execute_input":"2025-03-25T02:29:59.669820Z","iopub.status.idle":"2025-03-25T02:29:59.673993Z","shell.execute_reply.started":"2025-03-25T02:29:59.669788Z","shell.execute_reply":"2025-03-25T02:29:59.673119Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# pull out all the buildings actually used in the test set, given current method we don't need the other ones\nssubm = pd.read_csv('../input/indoor-location-navigation/sample_submission.csv')\n\n# only 24 of the total buildings are used in the test set, \n# this allows us to greatly reduce the intial size of the dataset\n\nssubm_df = ssubm[\"site_path_timestamp\"].apply(lambda x: pd.Series(x.split(\"_\")))\nused_buildings = sorted(ssubm_df[0].value_counts().index.tolist())\n\n# dictionary used to map the floor codes to the values used in the submission file. \nfloor_map = {\"B2\":-2, \"B1\":-1, \"F1\":0, \"F2\": 1, \"F3\":2, \"F4\":3, \"F5\":4, \"F6\":5, \"F7\":6,\"F8\":7, \"F9\":8,\n             \"1F\":0, \"2F\":1, \"3F\":2, \"4F\":3, \"5F\":4, \"6F\":5, \"7F\":6, \"8F\": 7, \"9F\":8}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T02:30:02.190142Z","iopub.execute_input":"2025-03-25T02:30:02.190554Z","iopub.status.idle":"2025-03-25T02:30:04.467863Z","shell.execute_reply.started":"2025-03-25T02:30:02.190517Z","shell.execute_reply":"2025-03-25T02:30:04.466753Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"print(used_buildings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T02:30:59.312184Z","iopub.execute_input":"2025-03-25T02:30:59.312586Z","iopub.status.idle":"2025-03-25T02:30:59.317290Z","shell.execute_reply.started":"2025-03-25T02:30:59.312549Z","shell.execute_reply":"2025-03-25T02:30:59.316356Z"}},"outputs":[{"name":"stdout","text":"['5a0546857ecc773753327266', '5c3c44b80379370013e0fd2b', '5d27075f03f801723c2e360f', '5d27096c03f801723c31e5e0', '5d27097f03f801723c320d97', '5d27099f03f801723c32511d', '5d2709a003f801723c3251bf', '5d2709b303f801723c327472', '5d2709bb03f801723c32852c', '5d2709c303f801723c3299ee', '5d2709d403f801723c32bd39', '5d2709e003f801723c32d896', '5da138274db8ce0c98bbd3d2', '5da1382d4db8ce0c98bbe92e', '5da138314db8ce0c98bbf3a0', '5da138364db8ce0c98bc00f1', '5da1383b4db8ce0c98bc11ab', '5da138754db8ce0c98bca82f', '5da138764db8ce0c98bcaa46', '5da1389e4db8ce0c98bd0547', '5da138b74db8ce0c98bd4774', '5da958dd46f8266d0737457b', '5dbc1d84c1eb61796cf7c010', '5dc8cea7659e181adb076a3f']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# get only the wifi bssid that occur over 1000 times(this number can be experimented with)\n# these will be the only ones used when constructing features\nbssid = dict()\n\nfor building in used_buildings:\n    folders = sorted(glob.glob(os.path.join(base_path,'train/'+building+'/*')))\n    print(building)\n    wifi = list()\n    for folder in folders:\n        floor = floor_map[folder.split('/')[-1]]\n        files = glob.glob(os.path.join(folder, \"*.txt\"))\n        for file in files:\n            with open(file) as f:\n                txt = f.readlines()\n                for e, line in enumerate(txt):\n                    tmp = line.strip().split()\n                    if tmp[1] == \"TYPE_WIFI\":\n                        wifi.append(tmp)\n    df = pd.DataFrame(wifi)\n    #top_bssid = df[3].value_counts().iloc[:500].index.tolist()\n    value_counts = df[3].value_counts()\n    top_bssid = value_counts[value_counts > 1000].index.tolist()\n    print(len(top_bssid))\n    #按照字典存储，key为building value 为出现次数>1000的的wifi \n    bssid[building] = top_bssid\n    del df\n    del wifi\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T02:31:17.434303Z","iopub.execute_input":"2025-03-25T02:31:17.434709Z","iopub.status.idle":"2025-03-25T02:44:43.602246Z","shell.execute_reply.started":"2025-03-25T02:31:17.434672Z","shell.execute_reply":"2025-03-25T02:44:43.601194Z"}},"outputs":[{"name":"stdout","text":"5a0546857ecc773753327266\n941\n5c3c44b80379370013e0fd2b\n867\n5d27075f03f801723c2e360f\n1805\n5d27096c03f801723c31e5e0\n311\n5d27097f03f801723c320d97\n396\n5d27099f03f801723c32511d\n220\n5d2709a003f801723c3251bf\n113\n5d2709b303f801723c327472\n614\n5d2709bb03f801723c32852c\n878\n5d2709c303f801723c3299ee\n273\n5d2709d403f801723c32bd39\n287\n5d2709e003f801723c32d896\n340\n5da138274db8ce0c98bbd3d2\n10\n5da1382d4db8ce0c98bbe92e\n998\n5da138314db8ce0c98bbf3a0\n653\n5da138364db8ce0c98bc00f1\n49\n5da1383b4db8ce0c98bc11ab\n621\n5da138754db8ce0c98bca82f\n237\n5da138764db8ce0c98bcaa46\n277\n5da1389e4db8ce0c98bd0547\n135\n5da138b74db8ce0c98bd4774\n1105\n5da958dd46f8266d0737457b\n1098\n5dbc1d84c1eb61796cf7c010\n1285\n5dc8cea7659e181adb076a3f\n562\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"with open(\"bssid_1000.json\", \"w\") as f:\n    json.dump(bssid, f)\n\nwith open(\"bssid_1000.json\") as f:\n    bssid = json.load(f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# generate all the training data \nbuilding_dfs = dict()\n\nfor building in used_buildings:\n    break\n    folders = sorted(glob.glob(os.path.join(base_path,'train', building +'/*')))\n    dfs = list()\n    index = sorted(bssid[building])\n    print(building)\n    for folder in folders:\n        floor = floor_map[folder.split('/')[-1]]\n        files = glob.glob(os.path.join(folder, \"*.txt\"))\n        print(floor)\n        for file in files:\n            wifi = list()\n            waypoint = list()\n            with open(file) as f:\n                txt = f.readlines()\n            for line in txt:\n                line = line.strip().split()\n                if line[1] == \"TYPE_WAYPOINT\":\n                    waypoint.append(line)\n                if line[1] == \"TYPE_WIFI\":\n                    wifi.append(line)\n            #存每一楼每一个层的wifi\n            df = pd.DataFrame(np.array(wifi))    \n\n            # generate a feature, and label for each wifi block\n            #相同时间的wifi 分为一组\n            #gid：表示当前分组的键值 时间（即第一列中的唯一值） g：表示当前分组对应的数据子集（一个小型数据框）。\n            for gid, g in df.groupby(0):\n                dists = list()\n                for e, k in enumerate(waypoint):\n                    dist = abs(int(gid) - int(k[0]))\n                    dists.append(dist)\n                nearest_wp_index = np.argmin(dists)\n                \n                g = g.drop_duplicates(subset=3)#按照bssid 删除相同值 因为同一个bssid 会有2g 和 5g\n                tmp = g.iloc[:,3:5]#取bssid rssi 和freq\n                feat = tmp.set_index(3).reindex(index).replace(np.nan, -999).T#根据bssid 设置为索引\n                feat[\"x\"] = float(waypoint[nearest_wp_index][2])\n                feat[\"y\"] = float(waypoint[nearest_wp_index][3])\n                feat[\"f\"] = floor\n                feat[\"path\"] = file.split('/')[-1].split('.')[0] # useful for crossvalidation\n                # feat 列为 bssid, rssid, fre, x,  y, floor,path  其中 x y是wifi 时间 找最近的waypoint  \n                dfs.append(feat)\n                \n    building_df = pd.concat(dfs)\n    building_dfs[building] = df\n    building_df.to_csv(building+\"_1000_train.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate the features for the test set\n\nssubm_building_g = ssubm_df.groupby(0)\nfeature_dict = dict()\n\nfor gid0, g0 in ssubm_building_g:\n    break\n    index = sorted(bssid[g0.iloc[0,0]])\n    feats = list()\n    print(gid0)\n    for gid,g in g0.groupby(1):\n\n        # get all wifi time locations, \n        with open(os.path.join(base_path, 'test/' + g.iloc[0,1] + '.txt')) as f:\n            txt = f.readlines()\n\n        wifi = list()\n\n        for line in txt:\n            line = line.strip().split()\n            if line[1] == \"TYPE_WIFI\":\n                wifi.append(line)\n\n        wifi_df = pd.DataFrame(wifi)\n        wifi_points = pd.DataFrame(wifi_df.groupby(0).count().index.tolist())\n        \n        for timepoint in g.iloc[:,2].tolist():\n\n            deltas = (wifi_points.astype(int) - int(timepoint)).abs()\n            min_delta_idx = deltas.values.argmin()\n            wifi_block_timestamp = wifi_points.iloc[min_delta_idx].values[0]\n            \n            wifi_block = wifi_df[wifi_df[0] == wifi_block_timestamp].drop_duplicates(subset=3)\n            feat = wifi_block.set_index(3)[4].reindex(index).fillna(-999)\n\n            feat['site_path_timestamp'] = g.iloc[0,0] + \"_\" + g.iloc[0,1] + \"_\" + timepoint\n            feats.append(feat)\n    feature_df = pd.concat(feats, axis=1).T\n    feature_df.to_csv(gid0+\"_1000_test.csv\")\n    feature_dict[gid0] = feature_df","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}